import os
import re
from dataclasses import dataclass
from datetime import datetime
from typing import List, Optional

BEST_RE = re.compile(r"^best_stories_(\d{8})\.md$")  # MMDDYYYY

@dataclass
class Entry:
    abs_path: str
    rel_url: str          # /hackernews/YYYY/MM/DD/best_stories_MMDDYYYY
    date_dir: str         # YYYY/MM/DD
    mmddyyyy: str         # MMDDYYYY
    dt: datetime          # parsed from folder or filename

def _try_parse_dt(date_dir: str, mmddyyyy: str) -> Optional[datetime]:
    # Prefer date_dir (YYYY/MM/DD) if valid
    try:
        y, m, d = date_dir.split("/")
        return datetime(int(y), int(m), int(d))
    except Exception:
        pass
    # Fallback to filename MMDDYYYY
    try:
        return datetime.strptime(mmddyyyy, "%m%d%Y")
    except Exception:
        return None

def _collect_best_entries(base_dir: str) -> List[Entry]:
    entries: List[Entry] = []
    if not os.path.isdir(base_dir):
        return entries

    # Walk hackernews/YYYY/MM/DD/
    for root, _, files in os.walk(base_dir):
        for fn in files:
            m = BEST_RE.match(fn)
            if not m:
                continue

            mmddyyyy = m.group(1)
            abs_path = os.path.join(root, fn)

            # Compute date_dir relative to base_dir
            rel_dir = os.path.relpath(root, base_dir).replace("\\", "/")  # YYYY/MM/DD
            # Ensure rel_dir looks like YYYY/MM/DD
            if rel_dir.startswith("."):
                continue

            dt = _try_parse_dt(rel_dir, mmddyyyy)
            if dt is None:
                continue

            rel_url = f"/{base_dir}/{rel_dir}/{fn[:-3]}"  # strip .md for nicer URL
            # Normalize multiple slashes
            rel_url = rel_url.replace("//", "/")

            entries.append(Entry(
                abs_path=abs_path,
                rel_url=rel_url,
                date_dir=rel_dir,
                mmddyyyy=mmddyyyy,
                dt=dt,
            ))

    # Sort by date desc, then by path desc
    entries.sort(key=lambda e: (e.dt, e.abs_path), reverse=True)
    return entries

def update_hackernews_index(
    base_dir: str = "hackernews",
    index_path: str = "hackernews/index.md",
    max_items: int = 30,
) -> str:
    """
    Regenerate hackernews/index.md listing latest best_stories files.
    Returns the generated markdown string.
    """
    entries = _collect_best_entries(base_dir)[:max_items]

    lines = []
    lines.append("---")
    lines.append("layout: default")
    lines.append("title: Hacker News (Daily)")
    lines.append("---")
    lines.append("")
    lines.append("# Hacker News (Daily)")
    lines.append("")
    lines.append("Daily scraped **Hacker News – Best Stories** (Markdown generated by GitHub Actions).")
    lines.append("")
    lines.append("## Latest Files")
    lines.append("")

    if not entries:
        lines.append("_No files found yet. Run the workflow once to generate the first file._")
    else:
        for e in entries:
            # Display label: YYYY-MM-DD
            label = e.dt.strftime("%Y-%m-%d")
            lines.append(f"- **{label}** — [{e.mmddyyyy}]({e.rel_url})")

    lines.append("")
    lines.append("## Browse by date")
    lines.append("")
    lines.append(f"- Folder: `/{base_dir}/YYYY/MM/DD/`")
    lines.append("")
    lines.append("> Tip: GitHub Pages may take a minute to reflect a fresh workflow run.")
    lines.append("")

    md = "\n".join(lines)

    os.makedirs(os.path.dirname(index_path), exist_ok=True)
    with open(index_path, "w", encoding="utf-8") as f:
        f.write(md)

    return md
